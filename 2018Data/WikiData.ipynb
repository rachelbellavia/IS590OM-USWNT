{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering player Wikipedia data\n",
    "\n",
    "## Part 1: Player Wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import time\n",
    "\n",
    "playerinfo = []\n",
    "with open(\"USWNT/playerdata.csv\", \"r\", newline = \"\") as infile:\n",
    "    csvin = csv.reader(infile)\n",
    "    headers = next(csvin)\n",
    "    for line in csvin:\n",
    "        playerinfo.append(line)\n",
    "\n",
    "filename = headers.index(\"Filename\")\n",
    "firstname = headers.index(\"Firstname\")\n",
    "surname = headers.index(\"Surname\")\n",
    "\n",
    "wikidata = []\n",
    "\n",
    "for singleplayer in playerinfo:\n",
    "    wikidatarow = []\n",
    "    playerfilename = singleplayer[filename]\n",
    "    playerfirstname = singleplayer[firstname]\n",
    "    playersurname = singleplayer[surname]\n",
    "\n",
    "    # Make Players' Wikipedia URLs\n",
    "    if playersurname == \"Campbell\" or playersurname == \"Smith\" or playersurname == \"Williams\" or playersurname == \"Fox\":\n",
    "        wikiplayerurl = \"https://en.wikipedia.org/wiki/\" + playerfirstname + \"_\" + playersurname + \"_(soccer)\"\n",
    "    else:\n",
    "        wikiplayerurl = \"https://en.wikipedia.org/wiki/\" + playerfirstname + \"_\" + playersurname\n",
    "    \n",
    "    # Make filenames to write the HTML from the Wikipedia pages\n",
    "    last_slash = wikiplayerurl.rindex(\"/\")\n",
    "    playerwikifilename = \"PlayerWiki\" + wikiplayerurl[last_slash:] + \".html\"\n",
    "    \n",
    "    # Request HTML from Wikipedia\n",
    "    outfile = open(playerwikifilename, \"w\")\n",
    "    result = requests.get(wikiplayerurl)\n",
    "    print(result.text, file=outfile)\n",
    "    outfile.close()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Collect player names and filenames to keep track of what's where\n",
    "    wikidatarow.append(playerfilename)\n",
    "    wikidatarow.append(playerfirstname)\n",
    "    wikidatarow.append(playersurname)\n",
    "    wikidatarow.append(playerwikifilename)\n",
    "    \n",
    "    wikidata.append(wikidatarow)\n",
    "\n",
    "# Write it out to a csv for preservation and accountability\n",
    "wikidataheaders = [\"Player Filename\", \"Firstname\", \"Surname\", \"PlayerWiki Filename\"]\n",
    "\n",
    "outfile = open('PlayerWiki/playerwikidata.csv', 'w')\n",
    "csv_out = csv.writer(outfile)\n",
    "csv_out.writerow(wikidataheaders)\n",
    "csv_out.writerows(wikidata)\n",
    "outfile.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Finding player college teams and the Wikipedia page for the teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "\n",
    "wikidata = []\n",
    "with open('PlayerWiki/playerwikidata.csv', \"r\", newline = \"\") as infile:\n",
    "    csvin = csv.reader(infile)\n",
    "    wikidataheaders = next(csvin)\n",
    "    for line in csvin:\n",
    "        wikidata.append(line)\n",
    "\n",
    "playerwikihtml = wikidataheaders.index(\"PlayerWiki Filename\")\n",
    "\n",
    "for playerwiki in wikidata:\n",
    "    playerwikihtmlfile = playerwiki[playerwikihtml]\n",
    "    infile = open(playerwikihtmlfile, \"r\")\n",
    "    page = infile.read()\n",
    "    tree = html.fromstring(page)\n",
    "    \n",
    "    headers = tree.xpath('//th[contains(@style,\"background-color: #b0c4de\")]')\n",
    "\n",
    "    counter = 0\n",
    "    for element in headers:\n",
    "        if element.text == \"College career\":\n",
    "            collegelocation = headers[counter]\n",
    "            nextheader = headers[counter + 1]\n",
    "        else:\n",
    "            pass\n",
    "        counter = counter + 1\n",
    "    try:\n",
    "        collegehtml = page[page.index(collegelocation.text):page.index(nextheader.text)]\n",
    "        littletree=html.fromstring(collegehtml)\n",
    "        collegelink = littletree.xpath('//a/@href')\n",
    "        for link in collegelink:\n",
    "            if link.startswith(\"#\") == True:\n",
    "                pass\n",
    "            else:\n",
    "                playerwiki.append(link[link.rindex('/'):])\n",
    "                \n",
    "    except:\n",
    "        playerwiki.append(\"NoCollege\")\n",
    "        \n",
    "\n",
    "\n",
    "wikidataheaders.append(\"First College Team Link\")\n",
    "wikidataheaders.append(\"Second College Team Link\")\n",
    "outfile = open('Collegeteam/collegeteamlinks.csv', 'w')\n",
    "csv_out = csv.writer(outfile)\n",
    "csv_out.writerow(wikidataheaders)\n",
    "csv_out.writerows(wikidata)\n",
    "outfile.close()    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# collegelinks = []\n",
    "# with open('Collegeteam/collegeteamlinks.csv', 'r', newline = \"\") as infile:\n",
    "#     csvin = csv.reader(infile)\n",
    "#     headers = next(csvin)\n",
    "#     for line in csvin:       \n",
    "#         collegelinks.append(line)\n",
    "\n",
    "# finalcollegelinks = []        \n",
    "# for links in collegelinks:\n",
    "#     actuallinks = links[1:]\n",
    "#     for actuallink in actuallinks:\n",
    "#         if actuallink.startswith(\"#\")==True:\n",
    "#             pass\n",
    "#         elif actuallink==\"NoCollege\":\n",
    "#             pass\n",
    "#         else:\n",
    "#             finalcollegelinks.append(actuallink[actuallink.rindex('/'):]) # Only grabs the end of the link for the filename, removing the /wiki portion\n",
    "\n",
    "# uniquecollegelinks = set(finalcollegelinks)            \n",
    "# outfile = open(\"Collegeteam/collegeteamurls.txt\", \"w\")\n",
    "# for link in uniquecollegelinks:\n",
    "#      print(link, file=outfile)\n",
    "# outfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "wikidata = []\n",
    "with open('Collegeteam/collegeteamlinks.csv', 'r', newline = \"\") as infile:\n",
    "    csvin = csv.reader(infile)\n",
    "    wikidataheaders = next(csvin)\n",
    "    for line in csvin:       \n",
    "        wikidata.append(line)\n",
    "        \n",
    "firstcollegeteam = wikidataheaders.index(\"First College Team Link\")\n",
    "secondcollegeteam = wikidataheaders.index(\"Second College Team Link\")\n",
    "\n",
    "for playerwiki in wikidata:\n",
    "    try:\n",
    "        secondcollege = playerwiki[secondcollegeteam]\n",
    "    except:\n",
    "        playerwiki.append(\"N/A\")\n",
    "    \n",
    "    firstcollege = playerwiki[firstcollegeteam]\n",
    "    secondcollege = playerwiki[secondcollegeteam]\n",
    "    \n",
    "    if firstcollege == \"NoCollege\":\n",
    "        playerwiki.append(\"N/A\")\n",
    "    else:\n",
    "        firstlinkbuild = \"https://en.wikipedia.org/wiki\" + firstcollege\n",
    "        outfile = open('Collegeteam' + firstcollege + '.html', 'w')\n",
    "        \n",
    "        result = requests.get(firstlinkbuild)\n",
    "        print(result.text, file=outfile)\n",
    "        time.sleep(2)\n",
    "        outfile.close()\n",
    "    \n",
    "    if secondcollege == \"N/A\":\n",
    "        pass\n",
    "    else:\n",
    "        secondlinkbuild = \"https://en.wikipedia.org/wiki\" + secondcollege\n",
    "        outfile = open('Collegeteam' + secondcollege + '.html', 'w')\n",
    "        \n",
    "        result = requests.get(secondlinkbuild)\n",
    "        print(result.text, file=outfile)\n",
    "        time.sleep(2)\n",
    "        outfile.close()\n",
    "    \n",
    "outfile = open('Collegeteam/collegeteamlinks.csv', 'w')\n",
    "csv_out = csv.writer(outfile)\n",
    "csv_out.writerow(wikidataheaders)\n",
    "csv_out.writerows(wikidata)\n",
    "outfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Finding the Wiki page for the actual university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "\n",
    "wikidata = []\n",
    "with open('Collegeteam/collegeteamlinks.csv', 'r', newline = \"\") as infile:\n",
    "    csvin = csv.reader(infile)\n",
    "    wikidataheaders = next(csvin)\n",
    "    for line in csvin:       \n",
    "        wikidata.append(line)\n",
    "\n",
    "firstcollegeteam = wikidataheaders.index(\"First College Team Link\")\n",
    "secondcollegeteam = wikidataheaders.index(\"Second College Team Link\")\n",
    "\n",
    "wikidataheaders.append(\"First College\")\n",
    "wikidataheaders.append(\"Second College\")\n",
    "\n",
    "for playerwiki in wikidata:\n",
    "    \n",
    "    firstcollege = playerwiki[firstcollegeteam]\n",
    "    secondcollege = playerwiki[secondcollegeteam]        \n",
    "        \n",
    "    if firstcollege == \"NoCollege\":\n",
    "        playerwiki.append(\"N/A\")\n",
    "    else:\n",
    "        infile = open('Collegeteam' + firstcollege + \".html\", 'rb')\n",
    "        page = infile.read()\n",
    "        tree=html.fromstring(page)    \n",
    "        college = tree.xpath('//tr[contains(th,\"University\")]/td/a/@href')\n",
    "        if college == []:\n",
    "            playerwiki.append('Collegewiki' + firstcollege)\n",
    "        for link in college:\n",
    "            else:\n",
    "                collegelink = 'Collegewiki' + link[link.rindex('/'):] # Removes the /wiki from the beginning of the url\n",
    "                playerwiki.append(collegelink)\n",
    "        \n",
    "    if secondcollege == \"N/A\":\n",
    "        playerwiki.append(\"N/A\")\n",
    "    else:\n",
    "        infile = open('Collegeteam' + secondcollege + \".html\", 'rb')\n",
    "        page = infile.read()\n",
    "        tree=html.fromstring(page)    \n",
    "        college = tree.xpath('//tr[contains(th,\"University\")]/td/a/@href')\n",
    "        for link in college:\n",
    "            collegelink = 'Collegewiki' + link[link.rindex('/'):] # Removes the /wiki from the beginning of the url\n",
    "            playerwiki.append(collegelink)\n",
    "        \n",
    "\n",
    "outfile = open('Collegewiki/collegelinks.csv', 'w')\n",
    "csv_out = csv.writer(outfile)\n",
    "csv_out.writerow(wikidataheaders)\n",
    "csv_out.writerows(wikidata)\n",
    "outfile.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata = []\n",
    "with open(\"Collegewiki/collegelinks.csv\", \"r\", newline = \"\") as infile:\n",
    "    csvin = csv.reader(infile)\n",
    "    wikidataheaders = next(csvin)\n",
    "    for line in csvin:\n",
    "        wikidata.append(line)\n",
    "\n",
    "firstcollege = wikidataheaders.index(\"First College\")\n",
    "secondcollege = wikidataheaders.index(\"Second College\")\n",
    "\n",
    "for playerwiki in wikidata:\n",
    "    firstcollegelink = playerwiki[firstcollege]\n",
    "    secondcollegelink = playerwiki[secondcollege]\n",
    "    \n",
    "    if firstcollegelink == \"N/A\":\n",
    "        pass\n",
    "    else:\n",
    "        firstcollegeurl = 'https://wikipedia.org/wiki' + firstcollegelink[firstcollegelink.rindex('/'):]\n",
    "        \n",
    "        outfile = open(firstcollegelink + '.html', 'w')\n",
    "        result = requests.get(firstcollegeurl)\n",
    "        print(result.text, file=outfile)\n",
    "        time.sleep(2)\n",
    "        outfile.close()\n",
    "    \n",
    "    if secondcollegelink == \"N/A\":\n",
    "        pass\n",
    "    else:\n",
    "        secondcollegeurl = 'https://wikipedia.org/wiki' + secondcollegelink[secondcollegelink.rindex('/'):]\n",
    "        \n",
    "        outfile = open(secondcollegelink + '.html', 'w')\n",
    "        result = requests.get(secondcollegeurl)\n",
    "        print(result.text, file=outfile)\n",
    "        time.sleep(2)\n",
    "        outfile.close()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata = []\n",
    "with open(\"Collegewiki/collegelinks.csv\", \"r\", newline = \"\") as infile:\n",
    "    csvin = csv.reader(infile)\n",
    "    wikidataheaders = next(csvin)\n",
    "    for line in csvin:\n",
    "        wikidata.append(line)\n",
    "\n",
    "firstcollege = wikidataheaders.index(\"First College\")\n",
    "secondcollege = wikidataheaders.index(\"Second College\")\n",
    "\n",
    "wikidataheaders.append(\"First College Name\")\n",
    "wikidataheaders.append(\"First College Public\")\n",
    "wikidataheaders.append(\"First College Private\")\n",
    "wikidataheaders.append(\"First College Community\")\n",
    "wikidataheaders.append(\"First College Location\")\n",
    "wikidataheaders.append(\"First College Enrollment\")\n",
    "\n",
    "wikidataheaders.append(\"Second College Name\")\n",
    "wikidataheaders.append(\"Second College Public\")\n",
    "wikidataheaders.append(\"Second College Private\")\n",
    "wikidataheaders.append(\"Second College Community\")\n",
    "wikidataheaders.append(\"Second College Location\")\n",
    "wikidataheaders.append(\"Second College Enrollment\")\n",
    "\n",
    "\n",
    "for playerwiki in wikidata:\n",
    "    firstcollegelink = playerwiki[firstcollege]\n",
    "    secondcollegelink = playerwiki[secondcollege]\n",
    "    \n",
    "    if firstcollegelink == \"N/A\":\n",
    "        for loop in range(5):\n",
    "            playerwiki.append(\"N/A\")\n",
    "\n",
    "    else:    \n",
    "        infile = open(firstcollegelink + '.html', 'rb')\n",
    "        page = infile.read()\n",
    "        tree=html.fromstring(page)    \n",
    "    \n",
    "        schoolname = tree.xpath('//h1/text()')\n",
    "        \n",
    "        if tree.xpath('//tr[contains(th,\"Type\")]/td/a[contains(text(),\"Public\")]/text()') == []:\n",
    "            publiccollege = 'n'\n",
    "        else:\n",
    "            publiccollege = 'y'\n",
    "        \n",
    "        if tree.xpath('//tr[contains(th,\"Type\")]/td/a[contains(text(),\"Private\")]/text()') == []:\n",
    "            privatecollege = 'n'\n",
    "        else:\n",
    "            privatecollege = 'y'\n",
    "            \n",
    "        if tree.xpath('//tr[contains(th,\"Type\")]/td/a[contains(text(),\"Community\")]/text()') == []:\n",
    "            communitycollege = 'n'\n",
    "        else:\n",
    "            communitycollege = 'y'\n",
    "            \n",
    "        students = tree.xpath('//tr[contains(th,\"Students\")]/td/text()')\n",
    "        location = tree.xpath('//tr[contains(th,\"Location\")]/td/div/a/text()')    \n",
    "    \n",
    "        playerwiki.append(\",\".join(schoolname))\n",
    "        playerwiki.append(publiccollege)\n",
    "        playerwiki.append(privatecollege)\n",
    "        playerwiki.append(communitycollege)\n",
    "        playerwiki.append(\",\".join(location))\n",
    "        playerwiki.append(\",\".join(students))\n",
    "\n",
    "\n",
    "    if secondcollegelink == \"N/A\":\n",
    "        for loop in range(5):\n",
    "            playerwiki.append(\"N/A\")\n",
    "\n",
    "    else:    \n",
    "        infile = open(secondcollegelink + '.html', 'rb')\n",
    "        page = infile.read()\n",
    "        tree=html.fromstring(page)    \n",
    "    \n",
    "        schoolname = tree.xpath('//h1/text()')\n",
    "        \n",
    "        if tree.xpath('//tr[contains(th,\"Type\")]/td/a[contains(text(),\"Public\")]/text()') == []:\n",
    "            publiccollege = 'n'\n",
    "        else:\n",
    "            publiccollege = 'y'\n",
    "        \n",
    "        if tree.xpath('//tr[contains(th,\"Type\")]/td/a[contains(text(),\"Private\")]/text()') == []:\n",
    "            privatecollege = 'n'\n",
    "        else:\n",
    "            privatecollege = 'y'\n",
    "            \n",
    "        if tree.xpath('//tr[contains(th,\"Type\")]/td/a[contains(text(),\"Community\")]/text()') == []:\n",
    "            communitycollege = 'n'\n",
    "        else:\n",
    "            communitycollege = 'y'\n",
    "            \n",
    "        students = tree.xpath('//tr[contains(th,\"Students\")]/td/text()')\n",
    "        location = tree.xpath('//tr[contains(th,\"Location\")]/td/div/a/text()')    \n",
    "    \n",
    "        playerwiki.append(\",\".join(schoolname))\n",
    "        playerwiki.append(publiccollege)\n",
    "        playerwiki.append(privatecollege)\n",
    "        playerwiki.append(communitycollege)\n",
    "\n",
    "        playerwiki.append(\",\".join(location))\n",
    "        playerwiki.append(\",\".join(students))\n",
    "\n",
    "\n",
    "outfile = open('Collegewiki/collegedata.csv', 'w')\n",
    "csv_out = csv.writer(outfile)\n",
    "csv_out.writerow(wikidataheaders)\n",
    "csv_out.writerows(wikidata)\n",
    "outfile.close()           \n",
    "        \n",
    "        \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
