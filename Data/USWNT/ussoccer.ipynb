{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USWNT Player Data Project\n",
    "\n",
    "## Rachel Bellavia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:\n",
    "\n",
    "Scrape the player names from the website to make URLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the stats page as html\n",
    "\n",
    "year = \"2009\"  # input the year for the stats you want\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"https://www.ussoccer.com/womens-national-team/stats/\" + year + \"-statistics\"\n",
    "\n",
    "outfile = open(year + \"/statspage.html\", \"w\")\n",
    "result = requests.get(url)\n",
    "print(result.text, file=outfile)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URLs from player names\n",
    "\n",
    "year = \"2015\"  # input the year for the stats you want\n",
    "\n",
    "from lxml import html\n",
    "import string\n",
    "\n",
    "def clean_line(line):\n",
    "    cleaned_line = line\n",
    "    for character in string.punctuation:\n",
    "        cleaned_line = cleaned_line.replace(character, \"\")\n",
    "    return cleaned_line\n",
    "\n",
    "infile = open(year + \"/statspage.html\", \"rb\")\n",
    "statshtml = infile.read()\n",
    "infile.close()\n",
    "\n",
    "tree = html.fromstring(statshtml)\n",
    "\n",
    "if year == \"2015\":\n",
    "    names = tree.xpath('//tbody/tr[(position()>1) and (position() < last()-1)]/td[1]/span/text()')\n",
    "else:\n",
    "    names = tree.xpath('//tbody/tr[(position()>1) and (position() < last()-1)]/td[1]/text()') # Pulls only the first column (player names), not including the last two lines, which are headers for totals\n",
    "\n",
    "uniquenames = set(names) # Remove duplicate names since goalies appear twice\n",
    "\n",
    "playernames = []\n",
    "for name in uniquenames:\n",
    "    if name.strip().lower() == 'own goal': # Filter out own goals from list of names\n",
    "        pass\n",
    "    elif name.strip().lower() == 'own goals received':\n",
    "        pass\n",
    "    elif name.strip().lower() == 'owngoal':\n",
    "        pass\n",
    "    elif name == '\\n            ':\n",
    "        pass\n",
    "    else:\n",
    "        playernames.append(name.lower().strip().replace(\" \", \"\").split(\",\")) # Splits name into first and last and makes lowercase\n",
    "        \n",
    "outfile = open(year + '/urls.txt', 'w')\n",
    "\n",
    "for lastname, firstname in playernames:\n",
    "    if lastname == 'ertz': # Exemption for Julie Ertz, whose url is her maiden name\n",
    "        playerurl = \"https://www.ussoccer.com/players/j/julie-johnston\"\n",
    "        print(playerurl, file=outfile)\n",
    "    elif lastname == 'vanhollebeke':\n",
    "        playerurl = \"https://www.ussoccer.com/players/b/rachel-buehler\"\n",
    "        print(playerurl, file=outfile)\n",
    "    elif lastname == 'loyden':\n",
    "        playerurl = \"https://www.ussoccer.com/players/l/jillian-loyden\"\n",
    "        print(playerurl, file=outfile)\n",
    "    elif firstname == 'leighann':\n",
    "        playerurl = \"https://www.ussoccer.com/players/r/lee-ann-robinson\"\n",
    "        print(playerurl, file=outfile)\n",
    "    elif lastname == 'cheney':\n",
    "        playerurl = \"https://www.ussoccer.com/players/h/lauren-holiday\"\n",
    "        print(playerurl, file=outfile)\n",
    "    elif lastname == 'kreiger':\n",
    "        playerurl = \"https://www.ussoccer.com/players/k/ali-krieger\"\n",
    "        print(playerurl, file=outfile)\n",
    "    elif lastname == 'nogueira':\n",
    "        playerurl = \"https://www.ussoccer.com/players/n/casey-noguiera\"\n",
    "        print(playerurl, file=outfile)\n",
    "    else:\n",
    "        playerurl = \"https://www.ussoccer.com/players/\" + lastname[0] + \"/\" + clean_line(firstname) + \"-\" + clean_line(lastname)\n",
    "        print(playerurl, file=outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "\n",
    "Ping the website to acquire files from player bio URLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through urls and saves html for each player bio page\n",
    "\n",
    "year = \"2015\"  # input the year for the stats you want\n",
    "\n",
    "import requests\n",
    "import time\n",
    "infile = open(year + '/urls.txt', \"r\")\n",
    "\n",
    "list_of_urls = infile.read().split()\n",
    "\n",
    "for url in list_of_urls:\n",
    "    last_slash = url.rindex(\"/\")\n",
    "    filename = year + \"/\" + url[last_slash + 1:] + \".html\" # Last slash pulls only the final part of the url, i.e. the player name, for the file name\n",
    "    outfile = open(filename, \"w\")\n",
    "\n",
    "    result = requests.get(url)\n",
    "    print(result.text, file=outfile)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:\n",
    "\n",
    "Read in the html files and organize the desired information into a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2015\"  # input the year for the stats you want\n",
    "\n",
    "from lxml import html\n",
    "\n",
    "def checkFor1Result(xpathresult, missing_value): # Function to catch any bio information field that might be blank\n",
    "    if len(xpathresult) > 1:\n",
    "        howmany = len(xpathresult)\n",
    "        raise ValueError(\"Your list had \" + str(howmany) + \" items instead of 1. Shutting down the program.\")\n",
    "    elif len(xpathresult) == 1:\n",
    "        result = xpathresult[0] # grab the element when there is exactly one to grab\n",
    "    else:\n",
    "        result = missing_value\n",
    "    return result\n",
    "\n",
    "infile = open(year + \"/urls.txt\", \"r\")\n",
    "list_of_urls = infile.read().split()\n",
    "infile.close()\n",
    "\n",
    "filenames = [] # Create the file names again, this time for reading instead of writing\n",
    "for url in list_of_urls:\n",
    "    last_slash = url.rindex(\"/\")\n",
    "    filename = year + \"/\" + url[last_slash + 1:] + \".html\"\n",
    "    filenames.append(filename)\n",
    "\n",
    "allplayers = []\n",
    "for playerfile in filenames:\n",
    "    infile = open(playerfile, 'rb')\n",
    "    playerhtml = infile.read()\n",
    "    infile.close()\n",
    "\n",
    "    tree = html.fromstring(playerhtml)\n",
    "\n",
    "    # Save the info we want to a variable\n",
    "    firstname = tree.xpath('//span[@itemprop = \"givenName\"]/text()') \n",
    "    lastname = tree.xpath('//span[@itemprop = \"familyName\"]/text()')\n",
    "    position = tree.xpath('//span[@class = \"bio-position\"]/text()')\n",
    "\n",
    "    bdate = tree.xpath('//div[starts-with(@class, \"player-details\")]//p//@datetime')\n",
    "    height = tree.xpath('//div[starts-with(@class, \"player-details\")]//p/span/text()')\n",
    "    hometown = tree.xpath('//div[starts-with(@class, \"player-details\")]//p[@itemprop = \"address\"]/text()')\n",
    "    club = tree.xpath('//div[starts-with(@class, \"player-details\")]//p[@itemprop = \"name\"]/text()')\n",
    "\n",
    "    allinfo = []\n",
    "    \n",
    "    # Put all of the info we want into a list\n",
    "    allinfo.append(playerfile)\n",
    "    allinfo.append(checkFor1Result(firstname, \"NoFirstName\"))\n",
    "    allinfo.append(checkFor1Result(lastname, \"NoLastName\"))\n",
    "    allinfo.append(checkFor1Result(position, \"NoPosition\"))\n",
    "\n",
    "    allinfo.append(checkFor1Result(bdate, \"NoBirthdate\"))\n",
    "    allinfo.append(checkFor1Result(height, \"NoHeight\"))\n",
    "    allinfo.append(checkFor1Result(hometown, \"NoHometown\"))\n",
    "    allinfo.append(checkFor1Result(club, \"NoClub\"))\n",
    "\n",
    "    # Put the list into a list of lists\n",
    "    allplayers.append(allinfo)\n",
    "\n",
    "# Write out all the player info to a csv file    \n",
    "import csv\n",
    "\n",
    "player_headers = ['Filename','Firstname', 'Surname', 'Position','Birthdate', 'Height', 'Hometown', 'Club']\n",
    "\n",
    "outfile = open(year + '/playerdata.csv', 'w')\n",
    "csv_out = csv.writer(outfile)\n",
    "csv_out.writerow(player_headers)\n",
    "csv_out.writerows(allplayers)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "Go back through previous years and pull the player info for those years into their own datasets.\n",
    "\n",
    "Then: do some stuff with it! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
